{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "cap = cv2.VideoCapture(\"zxsu_smartTV_29command/add_to_queue/add_to_queue1.avi\")\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "buffer = []\n",
    "\n",
    "count = 0\n",
    "retaining = True\n",
    "\n",
    "while (count < frame_count and retaining):\n",
    "    retaining, frame = cap.read()\n",
    "    frame = cv2.resize(frame,(120,60))\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "    frame = Image.fromarray(frame, 'RGB')\n",
    "    buffer.append(frame)\n",
    "    count += 1\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_videovision.torchvideotransforms import video_transforms, volume_transforms\n",
    "video_transform_list = [\n",
    "    # video_transforms.RandomRotation((7,7)),\n",
    "    # video_transforms.RandomResize((0.97,0.97)),\n",
    "    video_transforms.CenterCrop((46,92)),    # h,w\n",
    "    video_transforms.ColorJitter(0.3,0.3,0.3)]\n",
    "transforms = video_transforms.Compose(video_transform_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig=plt.figure(figsize=(8, 8))\n",
    "columns = 4\n",
    "rows = 5\n",
    "for i in range(1, columns*rows +1):\n",
    "    buffer_train = transforms(buffer)\n",
    "    img = buffer_train[4*i]\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(buffer[35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(buffer_train[35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(frame,axis = 2)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "for i in range(-100,100):\n",
    "    cap = cv2.VideoCapture(i)\n",
    "    print(i)\n",
    "    if cap.read()[0]:\n",
    "        break\n",
    "    else:\n",
    "        cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from dataset import VideoDataset\n",
    "from network import R2Plus1DClassifier\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = R2Plus1DClassifier(num_classes=28, layer_sizes=[2,2,2,2,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "checkpoint = torch.load(\"zxsuSmartTV60TV_alldata.pt_puremodel\")\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(10)\ntensor(10)\ntensor(10)\ntensor(10)\ntensor(10)\ntensor(10)\ntensor(10)\ntensor(10)\ntensor(10)\ntensor(10)\ntensor(10)\ntensor(10)\ntensor(10)\ntensor(10)\ntensor(10)\ntensor(10)\ntensor(10)\ntensor(10)\ntensor(10)\ntensor(10)\n"
     ]
    }
   ],
   "source": [
    "for f in os.listdir(\"features/like\"):\n",
    "    test = np.load(f\"features/like/{f}\")\n",
    "    print(model.linear(torch.tensor(test)).argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([72])"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "torch.tensor(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"test.npy\",model.res2plus1d(torch.zeros(1,3,50,50,50)).detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}